{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running importance analysis with Hail\n",
    "=====================================\n",
    "\n",
    "This is an *VariantSpark* example notebook.\n",
    "\n",
    "\n",
    "One of the main applications of VariantSpark is discovery of genomic variants correlated with a response variable (e.g. case vs control) using random forest gini importance.\n",
    "\n",
    "The `chr22_1000.vcf` is a very small sample of the chromosome 22 VCF file from the 1000 Genomes Project.\n",
    "\n",
    "`chr22-labels-hail.csv` is a CSV file with sample response variables (labels). In fact the labels directly represent the number of alternative alleles for each sample at a specific genomic position. E.g.: column x22_16050408 has labels derived from variants in chromosome 22 position 16050408. We would expect then that position 22:16050408 in the VCF file is strongly correlated with the label x22_16050408.\n",
    "\n",
    "Both data sets are located in the `..\\data` directory.\n",
    "\n",
    "This notebook demonstrates how to run importance analysis on these data with *VariantSpark* Hail integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Create a `HailContext` using `SparkContext` object (here injected as `sc`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using variant-spark jar at '/Users/szu004/dev/VariantSpark/target/variant-spark_2.11-0.3.0-SNAPSHOT-all.jar'\n",
      "using hail jar at '/Users/szu004/miniconda3/envs/vs-dev3.6/lib/python3.6/site-packages/hail/hail-all-spark.jar'\n",
      "using hail jar at /Users/szu004/miniconda3/envs/vs-dev3.6/lib/python3.6/site-packages/hail/hail-all-spark.jar\n",
      "Running on Apache Spark version 2.4.1\n",
      "SparkUI available at http://192.168.1.10:4041\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.16-6da0d3571629\n",
      "LOGGING: writing to /Users/szu004/dev/VariantSpark/examples/hail-20201218-1127-0.2.16-6da0d3571629.log\n"
     ]
    }
   ],
   "source": [
    "import hail as hl\n",
    "import varspark.hail as vshl\n",
    "vshl.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Load Hail variant dataset  `vds` from a sample `.vcf` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds = hl.import_vcf('../data/chr22_1000.vcf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Load labels into Hail table `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-18 11:27:17 Hail: INFO: Reading table to impute column types\n",
      "2020-12-18 11:27:17 Hail: INFO: Finished type imputation\n",
      "  Loading column 'sample' as type 'str' (imputed)\n",
      "  Loading column 'x22_16050408' as type 'int32' (imputed)\n",
      "  Loading column 'x22_16050612' as type 'str' (imputed)\n",
      "  Loading column 'x22_16050678' as type 'str' (imputed)\n",
      "  Loading column 'x22_16050984' as type 'int32' (imputed)\n",
      "  Loading column 'x22_16051107' as type 'int32' (imputed)\n",
      "  Loading column 'x22_16051249' as type 'int32' (imputed)\n",
      "  Loading column 'x22_16051347' as type 'int32' (imputed)\n",
      "  Loading column 'x22_16051453' as type 'int32' (imputed)\n",
      "  Loading column 'x22_16051477' as type 'int32' (imputed)\n",
      "  Loading column 'x22_16051480' as type 'int32' (imputed)\n",
      "2020-12-18 11:27:17 Hail: WARN: Name collision: field 'sample' already in object dict. \n",
      "  This field must be referenced with __getitem__ syntax: obj['sample']\n"
     ]
    }
   ],
   "source": [
    "labels = hl.import_table('../data/chr22-labels-hail.csv', impute = True, delimiter=\",\").key_by('sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Annotate dataset samples with labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-18 11:27:17 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\n",
      "2020-12-18 11:27:18 Hail: INFO: Coerced almost-sorted dataset\n",
      "2020-12-18 11:27:19 Hail: INFO: Coerced sorted dataset\n",
      "2020-12-18 11:27:19 Hail: INFO: Coerced sorted dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><thead style=\"font-weight: bold;\"><tr><td>s</td><td>label.x22_16050408</td><td>label.x22_16050612</td><td>label.x22_16050678</td><td>label.x22_16050984</td><td>label.x22_16051107</td><td>label.x22_16051249</td><td>label.x22_16051347</td><td>label.x22_16051453</td><td>label.x22_16051477</td><td>label.x22_16051480</td></tr>\n",
       "<tr><td>str</td><td>int32</td><td>str</td><td>str</td><td>int32</td><td>int32</td><td>int32</td><td>int32</td><td>int32</td><td>int32</td><td>int32</td></tr>\n",
       "</thead><tbody><tr><td>&quot;HG00096&quot;</td><td>0</td><td>&quot;hahaha&quot;</td><td>&quot;heheh&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "<tr><td>&quot;HG00097&quot;</td><td>1</td><td>&quot;ala ma&quot;</td><td>&quot;1&quot;</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td></tr>\n",
       "<tr><td>&quot;HG00099&quot;</td><td>1</td><td>&quot;1&quot;</td><td>&quot;1&quot;</td><td>0</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td></tr>\n",
       "</tbody></table><p>showing top 3 rows</p>\n"
      ],
      "text/plain": [
       "+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
       "| s         | label.x22_16050408 | label.x22_16050612 | label.x22_16050678 | label.x22_16050984 | label.x22_16051107 | label.x22_16051249 | label.x22_16051347 | label.x22_16051453 | label.x22_16051477 | label.x22_16051480 |\n",
       "+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
       "| str       |              int32 | str                | str                |              int32 |              int32 |              int32 |              int32 |              int32 |              int32 |              int32 |\n",
       "+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
       "| \"HG00096\" |                  0 | \"hahaha\"           | \"heheh\"            |                  0 |                  0 |                  0 |                  0 |                  0 |                  0 |                  0 |\n",
       "| \"HG00097\" |                  1 | \"ala ma\"           | \"1\"                |                  0 |                  1 |                  1 |                  1 |                  1 |                  0 |                  1 |\n",
       "| \"HG00099\" |                  1 | \"1\"                | \"1\"                |                  0 |                  1 |                  1 |                  1 |                  1 |                  0 |                  1 |\n",
       "+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
       "showing top 3 rows"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vds = vds.annotate_cols(label = labels[vds.s])\n",
    "vds.cols().show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Build the random forest model with `label.x22_16050408` as the respose variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-18 11:27:21 Hail: INFO: Loaded 1988 variables\n"
     ]
    }
   ],
   "source": [
    "rf_model = vshl.random_forest_model(y=vds.label['x22_16050408'],\n",
    "                x=vds.GT.n_alt_alleles(), seed = 13, mtry_fraction = 0.05, min_node_size = 5, max_depth = 10)\n",
    "rf_model.fit_trees(100, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Display the results: print OOB error calculated variable importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB error: 0.010073260073260074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-18 11:27:24 Hail: INFO: Coerced sorted dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><thead style=\"font-weight: bold;\"><tr><td>locus</td><td>alleles</td><td>importance</td></tr>\n",
       "<tr><td>locus&lt;GRCh37&gt;</td><td>array&lt;str&gt;</td><td>float64</td></tr>\n",
       "</thead><tbody><tr><td>22:16050408</td><td>[&quot;T&quot;,&quot;C&quot;]</td><td>3.67e+01</td></tr>\n",
       "<tr><td>22:16050678</td><td>[&quot;C&quot;,&quot;T&quot;]</td><td>2.60e+01</td></tr>\n",
       "<tr><td>22:16052838</td><td>[&quot;T&quot;,&quot;A&quot;]</td><td>1.89e+01</td></tr>\n",
       "<tr><td>22:16053197</td><td>[&quot;G&quot;,&quot;T&quot;]</td><td>1.55e+01</td></tr>\n",
       "<tr><td>22:16051882</td><td>[&quot;C&quot;,&quot;T&quot;]</td><td>1.49e+01</td></tr>\n",
       "<tr><td>22:16053727</td><td>[&quot;T&quot;,&quot;G&quot;]</td><td>1.42e+01</td></tr>\n",
       "<tr><td>22:16051480</td><td>[&quot;T&quot;,&quot;C&quot;]</td><td>1.40e+01</td></tr>\n",
       "<tr><td>22:16052656</td><td>[&quot;T&quot;,&quot;C&quot;]</td><td>1.35e+01</td></tr>\n",
       "<tr><td>22:16053797</td><td>[&quot;T&quot;,&quot;C&quot;]</td><td>9.84e+00</td></tr>\n",
       "<tr><td>22:16051107</td><td>[&quot;C&quot;,&quot;A&quot;]</td><td>9.22e+00</td></tr>\n",
       "</tbody></table><p>showing top 10 rows</p>\n"
      ],
      "text/plain": [
       "+---------------+------------+------------+\n",
       "| locus         | alleles    | importance |\n",
       "+---------------+------------+------------+\n",
       "| locus<GRCh37> | array<str> |    float64 |\n",
       "+---------------+------------+------------+\n",
       "| 22:16050408   | [\"T\",\"C\"]  |   3.67e+01 |\n",
       "| 22:16050678   | [\"C\",\"T\"]  |   2.60e+01 |\n",
       "| 22:16052838   | [\"T\",\"A\"]  |   1.89e+01 |\n",
       "| 22:16053197   | [\"G\",\"T\"]  |   1.55e+01 |\n",
       "| 22:16051882   | [\"C\",\"T\"]  |   1.49e+01 |\n",
       "| 22:16053727   | [\"T\",\"G\"]  |   1.42e+01 |\n",
       "| 22:16051480   | [\"T\",\"C\"]  |   1.40e+01 |\n",
       "| 22:16052656   | [\"T\",\"C\"]  |   1.35e+01 |\n",
       "| 22:16053797   | [\"T\",\"C\"]  |   9.84e+00 |\n",
       "| 22:16051107   | [\"C\",\"A\"]  |   9.22e+00 |\n",
       "+---------------+------------+------------+\n",
       "showing top 10 rows"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"OOB error: %s\" % rf_model.oob_error())\n",
    "impTable = rf_model.variable_importance()\n",
    "impTable.order_by(hl.desc(impTable.importance)).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally release the resouces (RAM) associated with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_model.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on using *VariantSpark* and the Python API and Hail integration please visit the [documentation](http://variantspark.readthedocs.io/en/latest/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
